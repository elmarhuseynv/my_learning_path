{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdfe0095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\hp\\anaconda3\\lib\\site-packages (9.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a43b9f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.image import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fbd334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_labels(image_paths):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        image = load_img(image_path, target_size=(32, 32),\n",
    "                         color_mode='grayscale')\n",
    "        image = img_to_array(image)\n",
    "\n",
    "        label = image_path.split(os.path.sep)[-2]\n",
    "        label = 'positive' in label\n",
    "        label = float(label)\n",
    "\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30cf0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network():\n",
    "    input_layer = Input(shape=(32, 32, 1))\n",
    "    x = Conv2D(filters=20,\n",
    "               kernel_size=(5, 5),\n",
    "               padding='same',\n",
    "               strides=(1, 1))(input_layer)\n",
    "    x = ELU()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2),\n",
    "                     strides=(2, 2))(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    x = Conv2D(filters=50,\n",
    "               kernel_size=(5, 5),\n",
    "               padding='same',\n",
    "               strides=(1, 1))(x)\n",
    "    x = ELU()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2),\n",
    "                     strides=(2, 2))(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=500)(x)\n",
    "    x = ELU()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9777577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_pattern = 'C:/Users/hp/Desktop/simple classifier to detect smile/SMILEsmileD-master/SMILEs/*/*/*.jpg'\n",
    "files_pattern = str(files_pattern)\n",
    "dataset_paths = [*glob.glob(files_pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26fb5a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_images_and_labels(dataset_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6da6dbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 13165\n",
      "Smile images: 3690.0\n",
      "Non-smile images: 9475.0\n"
     ]
    }
   ],
   "source": [
    "X /= 255.0\n",
    "total = len(y)\n",
    "total_positive = np.sum(y)\n",
    "total_negative = total - total_positive\n",
    "print(f'Total images: {total}')\n",
    "print(f'Smile images: {total_positive}')\n",
    "print(f'Non-smile images: {total_negative}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de086b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test,\n",
    " y_train, y_test) = train_test_split(X, y,\n",
    "                                     test_size=0.2,\n",
    "                                     stratify=y,\n",
    "                                     random_state=999)\n",
    "(X_train, X_val,\n",
    " y_train, y_val) = train_test_split(X_train, y_train,\n",
    "                                    test_size=0.2,\n",
    "                                    stratify=y_train,\n",
    "                                    random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9059444",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_network()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ccf515bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "264/264 [==============================] - 19s 69ms/step - loss: 1.7940 - accuracy: 0.7458 - val_loss: 3.5159 - val_accuracy: 0.4196\n",
      "Epoch 2/20\n",
      "264/264 [==============================] - 17s 63ms/step - loss: 0.9950 - accuracy: 0.8185 - val_loss: 0.3184 - val_accuracy: 0.8904\n",
      "Epoch 3/20\n",
      "264/264 [==============================] - 17s 64ms/step - loss: 0.8344 - accuracy: 0.8455 - val_loss: 0.3487 - val_accuracy: 0.8586\n",
      "Epoch 4/20\n",
      "264/264 [==============================] - 17s 63ms/step - loss: 0.7564 - accuracy: 0.8589 - val_loss: 0.9051 - val_accuracy: 0.8016\n",
      "Epoch 5/20\n",
      "264/264 [==============================] - 17s 66ms/step - loss: 0.6519 - accuracy: 0.8732 - val_loss: 0.3881 - val_accuracy: 0.8567\n",
      "Epoch 6/20\n",
      "264/264 [==============================] - 18s 67ms/step - loss: 0.6221 - accuracy: 0.8815 - val_loss: 0.2573 - val_accuracy: 0.9027\n",
      "Epoch 7/20\n",
      "264/264 [==============================] - 17s 64ms/step - loss: 0.5696 - accuracy: 0.8903 - val_loss: 0.2589 - val_accuracy: 0.9003\n",
      "Epoch 8/20\n",
      "264/264 [==============================] - 17s 64ms/step - loss: 0.5485 - accuracy: 0.8946 - val_loss: 0.2617 - val_accuracy: 0.9103\n",
      "Epoch 9/20\n",
      "264/264 [==============================] - 17s 64ms/step - loss: 0.5251 - accuracy: 0.8980 - val_loss: 0.3660 - val_accuracy: 0.8491\n",
      "Epoch 10/20\n",
      "264/264 [==============================] - 17s 65ms/step - loss: 0.5189 - accuracy: 0.9020 - val_loss: 0.2574 - val_accuracy: 0.9122\n",
      "Epoch 11/20\n",
      "264/264 [==============================] - 18s 68ms/step - loss: 0.5044 - accuracy: 0.9041 - val_loss: 0.2720 - val_accuracy: 0.9027\n",
      "Epoch 12/20\n",
      "264/264 [==============================] - 19s 74ms/step - loss: 0.5034 - accuracy: 0.9064 - val_loss: 0.3249 - val_accuracy: 0.8794\n",
      "Epoch 13/20\n",
      "264/264 [==============================] - 20s 77ms/step - loss: 0.4628 - accuracy: 0.9124 - val_loss: 0.4365 - val_accuracy: 0.8391\n",
      "Epoch 14/20\n",
      "264/264 [==============================] - 19s 71ms/step - loss: 0.4574 - accuracy: 0.9172 - val_loss: 0.3974 - val_accuracy: 0.8927\n",
      "Epoch 15/20\n",
      "264/264 [==============================] - 17s 66ms/step - loss: 0.4453 - accuracy: 0.9162 - val_loss: 0.2872 - val_accuracy: 0.8757\n",
      "Epoch 16/20\n",
      "264/264 [==============================] - 17s 63ms/step - loss: 0.4250 - accuracy: 0.9173 - val_loss: 0.2432 - val_accuracy: 0.9122\n",
      "Epoch 17/20\n",
      "264/264 [==============================] - 17s 63ms/step - loss: 0.4042 - accuracy: 0.9245 - val_loss: 0.2579 - val_accuracy: 0.9084\n",
      "Epoch 18/20\n",
      "264/264 [==============================] - 17s 65ms/step - loss: 0.4121 - accuracy: 0.9209 - val_loss: 0.3563 - val_accuracy: 0.8946\n",
      "Epoch 19/20\n",
      "264/264 [==============================] - 17s 63ms/step - loss: 0.3891 - accuracy: 0.9295 - val_loss: 0.2789 - val_accuracy: 0.8965\n",
      "Epoch 20/20\n",
      "264/264 [==============================] - 17s 63ms/step - loss: 0.3716 - accuracy: 0.9334 - val_loss: 0.2768 - val_accuracy: 0.9084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ef56d29d0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "model.fit(X_train, y_train,\n",
    "          validation_data=(X_val, y_val),\n",
    "          epochs=EPOCHS,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          class_weight={\n",
    "              1.0: total / total_positive,\n",
    "              0.0: total / total_negative\n",
    "          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebd69cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
